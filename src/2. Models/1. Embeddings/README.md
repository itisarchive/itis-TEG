# Text Embeddings â€” Interactive Educational Demo

Welcome to your hands-on exploration of text embeddings!
This module provides a comprehensive journey through embedding fundamentals â€”
from basic vector properties to advanced vector arithmetic â€” using **Azure OpenAI**.

## ðŸŽ¯ Learning Objectives

By completing this module, you will:

- Understand what embeddings are and how they encode semantic meaning
- Compare similarity metrics: cosine similarity, Euclidean distance, dot product
- Discover counter-intuitive patterns (why _catâ€“dog > catâ€“kitten_)
- See how context dramatically changes word relationships
- Visualize semantic clusters with PCA and t-SNE
- Master the famous _king âˆ’ man + woman â‰ˆ queen_ analogy
- Connect theory to real AI applications (search, recommendations, chatbots)

## ðŸ“š Module Content

### 1. Embeddings Basics (`1. embeddings_basics.py`)

**ðŸš€ Comprehensive script covering seven demos**

A standalone Python script that teaches every concept through practical examples:

| Demo | Topic                    | Key Takeaway                                           |
|------|--------------------------|--------------------------------------------------------|
| 1    | Basic Embeddings         | 1536-dimensional vectors, unit magnitude, statistics   |
| 2    | Word Similarity Analysis | Three metrics compared side-by-side                    |
| 3    | The Cat-Dog Mystery      | Statistical co-occurrence â‰  taxonomic logic            |
| 4    | Context Matters          | Phrases can reverse similarity rankings                |
| 5    | Semantic Clusters        | PCA visualization + intra/inter-cluster analysis       |
| 6    | Similarity Heatmap       | Full relationship matrix with most/least similar pairs |
| 7    | Vector Arithmetic        | Kingâ€“queen analogy, gender-role & conceptual analogies |

### 2. Notebook (`notebook_1.ipynb`)

The same material as `1. embeddings_basics.py` in an interactive Jupyter notebook format,
extended with a **t-SNE visualization** (section 5b) for comparison with PCA.

## ðŸ“ File Structure

```
1. Embeddings/
â”œâ”€â”€ 1. embeddings_basics.py   # Main educational script (7 demos)
â”œâ”€â”€ notebook_1.ipynb          # Interactive notebook (same content + t-SNE)
â”œâ”€â”€ README.md                 # This documentation
â”œâ”€â”€ pyproject.toml            # Dependencies and project configuration
â”œâ”€â”€ .env.example              # Template for environment variables
â”œâ”€â”€ .env                      # Your API credentials (not committed)
â”œâ”€â”€ semantic_clusters.png     # Generated PCA visualization
â”œâ”€â”€ similarity_heatmap.png    # Generated similarity heatmap
â””â”€â”€ uv.lock                   # Dependency lock file
```

## ðŸš€ Quick Start

### Prerequisites

- Python 3.13+
- Azure OpenAI resource with a deployed `text-embedding-3-small` model
  (see [Azure AI Foundry docs](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/create-resource?pivots=web-portal))

### Setup

```bash
# 1. Navigate to the module
cd "src/2. Models/1. Embeddings"

# 2. Install dependencies
uv sync

# 3. Create your .env from the template
cp .env.example .env
# Then fill in AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_KEY and OPENAI_API_VERSION
```

### Running the Examples

```bash
# Run the comprehensive demo script
uv run python "1. embeddings_basics.py"
```

For the notebook, open `notebook_1.ipynb` in your IDE or Jupyter and run cells sequentially.

## ðŸ› ï¸ Dependencies

Defined in `pyproject.toml`:

| Package         | Purpose                        | Min version |
|-----------------|--------------------------------|-------------|
| `openai`        | Azure OpenAI SDK               | â‰¥ 2.21.0    |
| `numpy`         | Vector operations              | â‰¥ 2.4.2     |
| `scikit-learn`  | Cosine similarity, PCA, t-SNE  | â‰¥ 1.8.0     |
| `matplotlib`    | Chart rendering                | â‰¥ 3.10.8    |
| `seaborn`       | Heatmap visualization          | â‰¥ 0.13.2    |
| `python-dotenv` | `.env` file loading            | â‰¥ 1.2.1     |

## ðŸ” Environment Variables

All scripts rely on three variables read automatically by the `AzureOpenAI` SDK
(see `.env.example`):

| Variable                | Description                            |
|-------------------------|----------------------------------------|
| `AZURE_OPENAI_ENDPOINT` | Your Azure OpenAI resource URL         |
| `AZURE_OPENAI_API_KEY`  | API key for authentication             |
| `OPENAI_API_VERSION`    | API version, e.g. `2025-04-01-preview` |

> âš ï¸ The model name `text-embedding-3-small` used in code must have
> a matching **deployment** in Azure AI Foundry.

## ðŸŽ“ Learning Path

1. **Read this README** â€” understand the module goals
2. **Set up your environment** â€” `.env` and dependencies
3. **Run `1. embeddings_basics.py`** â€” watch all seven demos execute
4. **Open `notebook_1.ipynb`** â€” step through cells interactively, experiment
5. **Study the generated PNGs** â€” `semantic_clusters.png` and `similarity_heatmap.png`
6. **Experiment** â€” try your own words, analogies, and context templates

## ðŸ’¡ Tips

- Never commit `.env` to version control â€” it contains your API key.
- Both the script and notebook use an **embedding cache** â€” re-running is cheap.
- The script saves charts to PNG files; the notebook renders them inline.
- Try adding your own word groups to the clustering demo for deeper insight.
- Run analogy tests with domain-specific terms to see where embeddings excel (and fail).

## ðŸš€ Next Steps

After mastering this module, continue with:

1. **Module 2.2 (LLMs)** â€” response objects, multi-provider usage with LangChain
2. **Module 3 (RAG)** â€” Retrieval Augmented Generation for knowledge-based AI
3. **Module 4 (Graphs)** â€” workflow automation with LangGraph
4. **Module 5 (Tools and Agents)** â€” autonomous AI agents
5. **Module 6 (MCP)** â€” Model Context Protocol for advanced integrations
